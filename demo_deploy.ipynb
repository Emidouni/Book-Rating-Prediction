{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from flask import Flask, jsonify, request\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'best_model.pkl'\n",
    "port = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://192.168.1.137:5001\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def do_prediction():\n",
    "    #loading saved model here in this python file\n",
    "    unpickler = pickle.Unpickler(open(file_name, 'rb'))\n",
    "    model = unpickler.load()\n",
    "\n",
    "    #creating data frame of JSON data\n",
    "    json = request.get_json()\n",
    "    train = pd.DataFrame(json, index=[0])\n",
    "    # predict\n",
    "    y_predict = model.predict(train)\n",
    "    res= {\"Predicted note of rmse\" : y_predict[0]}\n",
    "    return jsonify(res)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.137:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "###arabi try\n",
    "from flask import Flask, jsonify, request\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define the custom function in the global scope\n",
    "def simple_imputer(X):\n",
    "    return X.fillna(X.median())\n",
    "def scale(X):\n",
    "    std_dev = X.std()\n",
    "    if (std_dev == 0).all():\n",
    "        return X - X.mean()\n",
    "    return (X - X.mean()) / std_dev\n",
    "\n",
    "# Load the model after the function definition\n",
    "file_name = 'best_model.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def do_prediction():\n",
    "    try:\n",
    "        # Creating DataFrame from JSON data\n",
    "        data = request.get_json()\n",
    "        df = pd.DataFrame(data, index=[0])\n",
    "\n",
    "        # Predict\n",
    "        y_predict = model.predict(df)\n",
    "        res = {\"Predicted note of rmse\": y_predict[0]}\n",
    "        return jsonify(res)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    port = 5000\n",
    "    app.run(host='0.0.0.0', port=port)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "books_clean = pd.read_csv('books.csv',error_bad_lines=False,warn_bad_lines=False)\n",
    "books_clean['numberOfAuthors'] = books_clean['authors'].str.count('/')+1\n",
    "## fixing the two dates\n",
    "date_mapping = {\n",
    "    '11/31/2000': '12/01/2001',\n",
    "    '6/31/1982': '07/01/1982'\n",
    "}\n",
    "books_clean['publication_date'] = books_clean['publication_date'].replace(date_mapping)\n",
    "\n",
    "  \n",
    "books_clean['publication_date'] = pd.to_datetime(books_clean['publication_date'])\n",
    "\n",
    "    \n",
    "books_clean['day'] = books_clean['publication_date'].dt.day\n",
    "books_clean['month'] = books_clean['publication_date'].dt.month\n",
    "books_clean['year'] = books_clean['publication_date'].dt.year\n",
    "    \n",
    "def check_book_type(title):\n",
    "    \n",
    "    keywords = ['set', 'collection', 'boxed', 'volume', 'volumes', 'trilogy', '#1-', '1-3', '1-4', '1-5', '1-6', '1-7', '1-8', 'volume i', 'volume ii', '1-', '2-', '3-', '4-', '5-', '6-', '7-', '8-', 'series', '/']\n",
    "    for keyword in keywords:\n",
    "        if keyword in title.lower():\n",
    "            return '1'\n",
    "    return '0'\n",
    "books_clean['bookType'] = books_clean['title'].apply(check_book_type)\n",
    "language_counts = books_clean['language_code'].value_counts()\n",
    "books_clean['lang_code_new'] = books_clean['language_code'].apply(lambda x: 'others' if language_counts[x] < 15 else x)\n",
    "median_value = books_clean[books_clean['  num_pages'] != 0]['  num_pages'].median()\n",
    "books_clean['  num_pages'] = books_clean['  num_pages'].replace(0, median_value)\n",
    "json_data_list = []\n",
    "\n",
    "# Open the Gzip file in binary mode for reading\n",
    "with gzip.open('goodreads_book_genres_initial.json.gz', 'rb') as json_file:\n",
    "    for line in json_file:\n",
    "        # Decode each line and load the JSON\n",
    "        json_data = json.loads(line.decode('utf-8'))\n",
    "        json_data_list.append(json_data)\n",
    "\n",
    "# Convert the list of JSON objects into a DataFrame\n",
    "json_df = pd.DataFrame(json_data_list)\n",
    "\n",
    "books_clean.rename(columns={'bookID': 'book_id'}, inplace=True)\n",
    "json_df['book_id'] = json_df['book_id'].astype(int)\n",
    "books_clean_merged = pd.merge(books_clean, json_df, on=\"book_id\", how=\"left\")\n",
    "def get_max_key(d):\n",
    "    if isinstance(d, dict): \n",
    "        if d:  \n",
    "            return max(d, key=d.get)\n",
    "    return None  \n",
    "\n",
    "books_clean_merged['type'] = books_clean_merged['genres'].apply(get_max_key)\n",
    "books_clean_merged['type'].fillna('others', inplace=True)\n",
    "books_clean_merged['collaboration'] = books_clean_merged['numberOfAuthors'].apply(lambda x: 'Yes' if x > 1 else 'No')\n",
    "publisher_counts = books_clean_merged['publisher'].value_counts()\n",
    "\n",
    "\n",
    "def classify_publisher(count):\n",
    "    if count < 15:\n",
    "        return 'Rare'\n",
    "    elif count <= 100:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Famous'\n",
    "    \n",
    "books_clean_merged['publisher_class'] = books_clean_merged['publisher'].map(publisher_counts).apply(classify_publisher)\n",
    "columns_to_remove = ['average_rating','publisher','book_id', 'title', 'authors','isbn', 'isbn13','language_code','publication_date','numberOfAuthors','genres']\n",
    "\n",
    "train= books_clean_merged.drop(columns=columns_to_remove)\n",
    "train = train.rename(columns={'  num_pages': 'num_pages'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://localhost:5000/predict'\n",
    "dict_x = dict_x = train.iloc[0].to_dict()\n",
    "r = requests.post(url, json=dict_x)\n",
    "print(r.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
